{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777b801f",
   "metadata": {},
   "source": [
    "# Training a GPT model with a custom dataset:\n",
    "* [1. Import libraries](#heading1)\n",
    "* [2. Prepare dataset](#heading2)\n",
    "* [3. Initialize GPT model](#heading3)\n",
    "* [4. Training](#heading4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a424e",
   "metadata": {},
   "source": [
    "# 1. Import libraries <a class=\"anchor\" id=\"heading1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jadegpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872836e",
   "metadata": {},
   "source": [
    "# 2. Prepare dataset <a class=\"anchor\" id=\"heading2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b39cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "input_dir = 'C:\\\\data'\n",
    "data_file_name = \"input.txt\"\n",
    "\n",
    "data = jadegpt.open_dataset_file(input_dir, data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "split = 0.9\n",
    "\n",
    "train_data, val_data = jadegpt.split_dataset(data, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and export datasets to files\n",
    "use_gpt2_encoding = False # True: use gpt encoding; False: use custom encoding\n",
    "data_dir = 'C:\\\\data\\\\splits'\n",
    "train_file_name = 'train.bin'\n",
    "val_file_name = 'val.bin'\n",
    "meta_file_name = 'meta.pkl'\n",
    "\n",
    "jadegpt.export_data_to_files(data, train_data, val_data, use_gpt2_encoding, data_dir, train_file_name, val_file_name, meta_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337e744",
   "metadata": {},
   "source": [
    "# 3. Initialize GPT model <a class=\"anchor\" id=\"heading3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt model parameters\n",
    "n_layer = 6\n",
    "n_head = 6\n",
    "n_embd = 384\n",
    "dropout = 0.0\n",
    "bias = False\n",
    "block_size = 32\n",
    "\n",
    "# get vocab size\n",
    "vocab_size = jadegpt.get_vocab_size(data)\n",
    "\n",
    "# random seed\n",
    "random_seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = jadegpt.init_gpt(random_seed, n_layer, n_head, n_embd, dropout, bias, block_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece9e6b",
   "metadata": {},
   "source": [
    "# 4. Training <a class=\"anchor\" id=\"heading4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data files to memory-map\n",
    "train_data = jadegpt.load_data_file_to_memmap(data_dir, train_file_name)\n",
    "val_data = jadegpt.load_data_file_to_memmap(data_dir, val_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8e41c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "# training\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 5\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc.\n",
    "dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16'\n",
    "# evaluation\n",
    "eval_interval = 50\n",
    "eval_iters = 20\n",
    "log_interval = 10\n",
    "# adamw optimizer\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n",
    "# learning rate decay settings\n",
    "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
    "max_iters = 100\n",
    "decay_lr = True # whether to decay the learning rate\n",
    "warmup_iters = 10 # not super necessary potentially\n",
    "lr_decay_iters = max_iters # make equal to max_iters usually\n",
    "min_lr = learning_rate / 10.0 # learning_rate / 10 usually\n",
    "# saving checkpoint\n",
    "only_save_on_finish = False\n",
    "save_interval = 50\n",
    "model_dir = 'C:\\\\model'\n",
    "model_name = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "jadegpt.train_gpt(model, dtype, device, train_data, val_data, block_size, batch_size,\\\n",
    "                  max_iters, weight_decay, learning_rate, beta1, beta2, warmup_iters,\\\n",
    "                  lr_decay_iters, min_lr, decay_lr, eval_interval, eval_iters,\\\n",
    "                  gradient_accumulation_steps, grad_clip, log_interval,\\\n",
    "                  only_save_on_finish, save_interval, model_dir, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
