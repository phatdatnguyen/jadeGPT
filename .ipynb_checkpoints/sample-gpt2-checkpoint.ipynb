{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0690d34d",
   "metadata": {},
   "source": [
    "# Generate text from pretrained GPT-2 model\n",
    "* [1. Import libraries](#heading1)\n",
    "* [2. Initialize GPT model](#heading2)\n",
    "* [3. Generate text](#heading3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3fc99",
   "metadata": {},
   "source": [
    "# 1. Import libraries <a class=\"anchor\" id=\"heading1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jadegpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d823dca1",
   "metadata": {},
   "source": [
    "# 2. Initialize GPT model <a class=\"anchor\" id=\"heading2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose gpt2 model\n",
    "gpt2_model = 'gpt2-xl' # 'gpt2', 'gpt2-medium', 'gpt2-large', or 'gpt2-xl'\n",
    "# random seed\n",
    "random_seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13401987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = jadegpt.init_gpt2(gpt2_model, random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee493d",
   "metadata": {},
   "source": [
    "# 3. Generate text from the model <a class=\"anchor\" id=\"heading3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = \"life is beautiful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfb285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "use_gpt2_encoding = True # True: use gpt encoding; False: use custom encoding\n",
    "meta_dir = ''\n",
    "meta_file_name = ''\n",
    "num_samples = 3 # number of samples to draw\n",
    "max_new_tokens = 100 # number of tokens generated in each sample\n",
    "temperature = 1.0 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 20 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc.\n",
    "dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d28c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text\n",
    "jadegpt.generate_text(model, prompt, use_gpt2_encoding, meta_dir, meta_file_name, num_samples, max_new_tokens, temperature, top_k, device, dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
