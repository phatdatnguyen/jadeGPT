{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb243b5c",
   "metadata": {},
   "source": [
    "# Finetune a GPT model\n",
    "* [1. Import libraries](#heading1)\n",
    "* [2. Prepare dataset](#heading2)\n",
    "* [3. Load GPT model](#heading3)\n",
    "    * [3.1. Pretrained GPT2 model](#heading3-1)\n",
    "    * [3.2. Load checkpoint](#heading3-2)\n",
    "* [4. Training](#heading4)\n",
    "* [5. Generate text](#heading5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bee10",
   "metadata": {},
   "source": [
    "# 1. Import libraries <a class=\"anchor\" id=\"heading1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jadegpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636bb42a",
   "metadata": {},
   "source": [
    "# 2. Prepare dataset <a class=\"anchor\" id=\"heading2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1755b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "input_dir = 'C:\\\\data'\n",
    "data_file_name = 'input.txt'\n",
    "\n",
    "data = jadegpt.open_dataset_file(input_dir + '\\\\' + data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58286690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "split = 0.9\n",
    "\n",
    "train_data, val_data = jadegpt.split_dataset(data, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and export datasets to files\n",
    "use_gpt2_encoding = True # True: use gpt encoding; False: use custom encoding\n",
    "data_dir = 'C:\\\\data'\n",
    "train_file_name = 'train.bin'\n",
    "val_file_name = 'val.bin'\n",
    "meta_file_name = 'meta.pkl'\n",
    "\n",
    "jadegpt.export_data_to_files(data, train_data, val_data, use_gpt2_encoding, data_dir, train_file_name, val_file_name, meta_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab04458",
   "metadata": {},
   "source": [
    "# 3. Load GPT model <a class=\"anchor\" id=\"heading3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecf473",
   "metadata": {},
   "source": [
    "## 3.1. Load from a pretrain GPT2 model  <a class=\"anchor\" id=\"heading3-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ceea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose gpt2 model\n",
    "gpt2_model = 'gpt2' # 'gpt2', 'gpt2-medium', 'gpt2-large', or 'gpt2-xl'\n",
    "# random seed\n",
    "random_seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = jadegpt.init_gpt2(gpt2_model, random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfad3f3",
   "metadata": {},
   "source": [
    "## 3.2. Load a checkpoint <a class=\"anchor\" id=\"heading3-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_dir = 'C:\\\\model'\n",
    "model_file_name = 'model-100.ckpt'\n",
    "\n",
    "# random seed\n",
    "random_seed = 1337\n",
    "# choose device\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7535f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume the model\n",
    "model = jadegpt.resume_gpt(model_dir + '\\\\' + model_file_name, random_seed, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91690c35",
   "metadata": {},
   "source": [
    "# 4. Fine-tuning <a class=\"anchor\" id=\"heading4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data files to memory-map\n",
    "train_data = jadegpt.load_data_file_to_memmap(data_dir, train_file_name)\n",
    "val_data = jadegpt.load_data_file_to_memmap(data_dir, val_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "# training\n",
    "batch_size = 8\n",
    "block_size = 32\n",
    "gradient_accumulation_steps = 5\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc.\n",
    "dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16'\n",
    "# evaluation\n",
    "eval_interval = 50\n",
    "eval_iters = 20\n",
    "log_interval = 10\n",
    "# adamw optimizer\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n",
    "# learning rate decay settings\n",
    "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
    "max_iters = 100\n",
    "decay_lr = True # whether to decay the learning rate\n",
    "warmup_iters = 10 # not super necessary potentially\n",
    "lr_decay_iters = max_iters # make equal to max_iters usually\n",
    "min_lr = learning_rate / 10.0 # learning_rate / 10 usually\n",
    "# saving checkpoint\n",
    "only_save_on_finish = False\n",
    "save_interval = 50\n",
    "model_dir = 'C:\\\\model'\n",
    "model_name = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea05543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning\n",
    "jadegpt.train_gpt(model, dtype, device, train_data, val_data, block_size, batch_size,\\\n",
    "                  max_iters, weight_decay, learning_rate, beta1, beta2, warmup_iters,\\\n",
    "                  lr_decay_iters, min_lr, decay_lr, eval_interval, eval_iters,\\\n",
    "                  gradient_accumulation_steps, grad_clip, log_interval,\\\n",
    "                  only_save_on_finish, save_interval, model_dir, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287a210",
   "metadata": {},
   "source": [
    "## 5. Generate text from fine-tuned model <a class=\"anchor\" id=\"heading5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "meta_dir = 'C:\\\\data'\n",
    "meta_file_name = 'meta.pkl'\n",
    "num_samples = 3 # number of samples to draw\n",
    "max_new_tokens = 100 # number of tokens generated in each sample\n",
    "temperature = 1.0 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 20 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc.\n",
    "dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f969e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text\n",
    "jadegpt.generate_text(model, prompt, use_gpt2_encoding, meta_dir, meta_file_name, num_samples, max_new_tokens, temperature, top_k, device, dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
