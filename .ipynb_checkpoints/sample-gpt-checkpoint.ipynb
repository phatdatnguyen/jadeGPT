{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8fd1d4",
   "metadata": {},
   "source": [
    "# Generate text from a GPT model checkpoint:\n",
    "* [1. Import libraries](#heading1)\n",
    "* [2. Initialize GPT model](#heading2)\n",
    "* [3. Generate text](#heading3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6c1ce",
   "metadata": {},
   "source": [
    "# 1. Import libraries <a class=\"anchor\" id=\"heading1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jadegpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be96e8",
   "metadata": {},
   "source": [
    "# 2. Initialize GPT model from a checkpoint <a class=\"anchor\" id=\"heading2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_dir = 'C:\\\\model'\n",
    "model_file_name = 'model-100.ckpt'\n",
    "\n",
    "# random seed\n",
    "random_seed = 1337\n",
    "# choose device\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume the model\n",
    "model = jadegpt.resume_gpt(model_dir + '\\\\' + model_file_name, random_seed, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea532a",
   "metadata": {},
   "source": [
    "# 3. Generate text from the model <a class=\"anchor\" id=\"heading3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6171daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a402535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "use_gpt2_encoding = False # True: use gpt encoding; False: use custom encoding\n",
    "meta_dir = 'C:\\\\data'\n",
    "meta_file_name = 'meta.pkl'\n",
    "num_samples = 3 # number of samples to draw\n",
    "max_new_tokens = 100 # number of tokens generated in each sample\n",
    "temperature = 1.0 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 20 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "device = 'cuda' # 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc.\n",
    "dtype = 'bfloat16' # 'float32', 'bfloat16', or 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text\n",
    "jadegpt.generate_text(model, prompt, use_gpt2_encoding, meta_dir, meta_file_name, num_samples, max_new_tokens, temperature, top_k, device, dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
